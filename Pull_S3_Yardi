import s3fs
import pandas as pd

BUCKET = "mvsgvtest"

URI = 's3://mvsgvtest/bank_credit_transactions/reconciled/08.2025.csv'
base_prefix = 'yardi_transactions'
fs = s3fs.S3FileSystem()


def read_periods(bucket: str, base_prefix: str, periods: list[str]) -> pd.DataFrame:

    df_list = []
    for p in periods:
        p = p.replace("/", ".")
        pattern = (f"s3://{bucket}/{base_prefix}/reconciled/{p}.csv")
        with fs.open(pattern, "r") as f:
            df =  pd.read_csv(f)
        df_list.append(df)

        # If no files were found, return an empty DataFrame
    if not df_list:
        print("No files were located")
        return pd.DataFrame()

    # Combine all DataFrames into one
    combined = pd.concat(df_list, ignore_index=True)

    return combined



#df = read_periods(bucket=BUCKET,base_prefix=base_prefix,periods=['08/2025'])

def load_S3_yardi(periods,bucket=BUCKET,base_prefix= base_prefix):
    aws_df = read_periods(bucket = bucket, base_prefix=base_prefix,periods=periods)
    aws_df['period'] = pd.to_datetime(aws_df['period'], format="%m/%d/%y", errors='coerce')
    aws_df['period'] = pd.to_datetime(aws_df['period']).dt.strftime('%m/%Y')
    aws_df["gl_code"] = aws_df["gl_code"].astype(int)

    aws_df['debit'] = (
        aws_df['debit']
            .astype(str).str.replace(',', '', regex=False).str.strip()
    ).pipe(pd.to_numeric, errors='coerce').fillna(0.0)

    aws_df['credit'] = (
        aws_df['credit']
            .astype(str).str.replace(',', '', regex=False).str.strip()
    ).pipe(pd.to_numeric, errors='coerce').fillna(0.0)

    return aws_df


